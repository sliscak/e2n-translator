{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "english2narsese.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVAr+mh66uhjraYlbazOVB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bfac356de594f728c06484b2297a8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0163878c68e04f7688236189b76855e6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f35cc541566349ca92e696ee32581eda",
              "IPY_MODEL_39b4df71df544baba56b5572f6d11160"
            ]
          }
        },
        "0163878c68e04f7688236189b76855e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "f35cc541566349ca92e696ee32581eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34a7532c35e24b1d8ed51a205d56884a",
            "_dom_classes": [],
            "description": "Epoch 4:   3%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 31,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21b7d9fb38344af99df1849909e680b4"
          }
        },
        "39b4df71df544baba56b5572f6d11160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e1dd1a1e00b4f859be0b39e86d90bc7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/31 [00:04&lt;02:13,  4.46s/it, loss=0.019, v_num=346]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f79ed86287b472eabde5f23c5343b9c"
          }
        },
        "34a7532c35e24b1d8ed51a205d56884a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21b7d9fb38344af99df1849909e680b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e1dd1a1e00b4f859be0b39e86d90bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f79ed86287b472eabde5f23c5343b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sliscak/e2n-translator/blob/main/english2narsese.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knmw2llO-PLA"
      },
      "source": [
        "INSTALL PREREQ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvjzc_RI-N7N"
      },
      "source": [
        "%%capture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#!cp \"/content/drive/My Drive/research/datasets/dataset.jsonl\" \"/content\"\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "!pip install ./transformers\n",
        "!pip install -U nlp\n",
        "!pip install pytorch-lightning\n",
        "!pip install tqdm\n",
        "\n",
        "!rm e2n-translator -rf\n",
        "!git clone https://github.com/sliscak/e2n-translator.git\n",
        "!python e2n-translator/dataset/build.py"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOhPFCN3-XNu"
      },
      "source": [
        "IMPORT PACKAGES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy_Gz53V-Wre"
      },
      "source": [
        "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, Trainer, TrainingArguments, T5Config, AdamW #T5WithLMHeadModel\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import json\n",
        "import nlp\n",
        "from pytorch_lightning.core.lightning import LightningModule\n",
        "import pytorch_lightning as pl\n",
        "from os import path\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9gHxcTSFioc"
      },
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "PATH = \"/content/drive/My Drive/research/models/t5-py\"\n",
        "# model = T5ForConditionalGeneration.from_pretrained('t5-base')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE7WPMD9_0ze",
        "outputId": "5dc476f0-ea9c-406c-f170-d6b0f001b805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        " class PythonDataset(Dataset):\n",
        "    \"\"\"Python dataset.\"\"\"\n",
        "    \"\"\"Either preprocess or process data on the fly\"\"\"\n",
        "\n",
        "    def __init__(self, file_path=\"/content/dataset.txt\"):\n",
        "      self.data = []\n",
        "      with open(file_path, 'r') as fd:\n",
        "        pair = []\n",
        "        for line in tqdm(fd.readlines(), desc='Dataset Loading'):\n",
        "          if len(line) > 3:\n",
        "              pair.append(line)\n",
        "              if len(pair) >= 2:\n",
        "                self.data.append(pair)\n",
        "                pair = [] \n",
        "        # else:\n",
        "        #   for line in tqdm(fd.readlines(), desc='Dataset Loading'):\n",
        "        #     # TODO: remove this part\n",
        "        #     if len(line) > 3:\n",
        "        #       self.data.append(line)\n",
        "\n",
        "    def process(self, pair):\n",
        "        with torch.no_grad():\n",
        "          text, narsese = pair\n",
        "          pattern = f'translate TEXT to NARSESE: \"{text}\"'\n",
        "\n",
        "          input_ids = tokenizer.encode(pattern, padding=True, truncation=True, return_tensors='pt')\n",
        "          labels = tokenizer.encode(narsese, padding=True, truncation=True, return_tensors='pt')\n",
        "          sample = {\n",
        "              \"input_ids\": input_ids,\n",
        "              \"labels\": labels,\n",
        "          }\n",
        "          return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        # print(self.data[idx])\n",
        "        # processing on the fly\n",
        "        return self.process(self.data[idx])\n",
        "\n",
        "dataset = PythonDataset()\n",
        "dataset[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Loading: 100%|██████████| 62/62 [00:00<00:00, 309211.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[13959,     3,  3463,     4,   382,    12,   445, 25210,  3205,   427,\n",
              "             10,    96,   667,   210,    40,    19,     3,     9,   686,    13,\n",
              "           2586,     5,    96,     1]]),\n",
              " 'labels': tensor([[    3,     2,  2381,    40,     3,    18, 13114,  2586,  3155,     5,\n",
              "              1]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vDJFSLGCtIl"
      },
      "source": [
        "class Pavian(LightningModule):\n",
        "  def __init__(self): # reset=False\n",
        "    super().__init__()\n",
        "    self.model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "    self.model.train()\n",
        "    # self.save_hyperparameters()\n",
        "\n",
        "  def forward(self, kwargs):\n",
        "    return self.model(**kwargs)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "        optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "        return optimizer\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "        for key in batch.keys():\n",
        "          batch[key] = batch[key][0]\n",
        "        outputs = self(batch)\n",
        "        loss = outputs[0]\n",
        "        tensorboard_logs = {'train_loss': loss}\n",
        "        return {'loss': loss, 'log': tensorboard_logs}\n",
        "\n",
        "\n",
        "  # def validation_step(self, batch, batch_idx):\n",
        "  #       x, y = batch\n",
        "  #       y_hat = self(x)\n",
        "  #       val_loss = F.cross_entropy(y_hat, y)\n",
        "  #       return val_loss\n",
        "model = Pavian()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4_PnzUmPHXD",
        "outputId": "16d57fca-7081-4f6c-c3c0-0261b58561f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405,
          "referenced_widgets": [
            "0bfac356de594f728c06484b2297a8d5",
            "0163878c68e04f7688236189b76855e6",
            "f35cc541566349ca92e696ee32581eda",
            "39b4df71df544baba56b5572f6d11160",
            "34a7532c35e24b1d8ed51a205d56884a",
            "21b7d9fb38344af99df1849909e680b4",
            "7e1dd1a1e00b4f859be0b39e86d90bc7",
            "3f79ed86287b472eabde5f23c5343b9c"
          ]
        }
      },
      "source": [
        "config = {\n",
        "    # 'gpus': 1, # uncomment to use GPU\n",
        "    'default_root_dir': '/content/drive/My Drive/research/checkpoints',\n",
        "    'checkpoint_callback': False,\n",
        "    'max_epochs': 10,\n",
        "    # 'precision':16,\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "train_loader = DataLoader(PythonDataset(), batch_size=1, shuffle=True)\n",
        "\n",
        "trainer = pl.Trainer(**config)\n",
        "trainer.fit(model, train_loader)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Loading: 100%|██████████| 62/62 [00:00<00:00, 336848.25it/s]\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "\n",
            "  | Name  | Type                       | Params\n",
            "-----------------------------------------------------\n",
            "0 | model | T5ForConditionalGeneration | 222 M \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bfac356de594f728c06484b2297a8d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
            "Please use self.log(...) inside the lightningModule instead.\n",
            "\n",
            "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
            "# (inside LightningModule)\n",
            "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MqRmf3WHFbu"
      },
      "source": [
        "# PATH = \"/content/drive/My Drive/research/models/t5-py\"\n",
        "# torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3WvE3iZgG2v",
        "outputId": "176302b4-e86d-42d5-ab46-53ba5d6a91f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "    text = '<cat --> animal>.'\n",
        "    pattern = f'translate TEXT to NARSESE: \"Cat is a type of animal.\"'\n",
        "    input_ids2 = tokenizer.encode(pattern, return_tensors='pt')\n",
        "    outputs2 = model.model.generate(input_ids2)\n",
        "    dec = tokenizer.decode(outputs2[0])\n",
        "    print(f'Input:\\n\\t{pattern}\\nOutput:\\n\\t{dec}\\n')\n",
        "    print(f'Ground Truth:\\n\\t{text}')\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:\n",
            "\ttranslate TEXT to NARSESE: \"Cat is a type of animal.\"\n",
            "Output:\n",
            "\t ⁇ cat --> animal>.\n",
            "\n",
            "Ground Truth:\n",
            "\t<cat --> animal>.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXrQNgnPMqP_"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}